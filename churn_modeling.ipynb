{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "985abe58",
   "metadata": {},
   "source": [
    "# Customer Churn Prediction â€“ Modeling Phase\n",
    "\n",
    "This notebook develops and evaluates predictive models using the cleaned Telco Customer Churn dataset.  \n",
    "Two models will be implemented and compared:\n",
    "\n",
    "- Logistic Regression  \n",
    "- Random Forest Classifier\n",
    "\n",
    "The evaluation metrics include:\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- ROC-AUC Score\n",
    "- ROC Curve Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6a4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score,\n",
    "    f1_score, roc_auc_score, classification_report, roc_curve\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f55506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned dataset\n",
    "df = pd.read_csv(\"cleaned_telco_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138a5ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df.drop(columns=['Churn_Yes'])\n",
    "y = df['Churn_Yes']\n",
    "\n",
    "# Split into train/test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb95f3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train models\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eccc55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "# Probabilities\n",
    "y_prob_logreg = logreg.predict_proba(X_test)[:, 1]\n",
    "y_prob_rf = rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "def evaluate_model(name, y_true, y_pred, y_prob):\n",
    "    print(f\"\\nðŸ“Š {name} Performance:\")\n",
    "    print(\"Accuracy:\", round(accuracy_score(y_true, y_pred), 4))\n",
    "    print(\"Precision:\", round(precision_score(y_true, y_pred), 4))\n",
    "    print(\"Recall:\", round(recall_score(y_true, y_pred), 4))\n",
    "    print(\"F1 Score:\", round(f1_score(y_true, y_pred), 4))\n",
    "    print(\"ROC AUC:\", round(roc_auc_score(y_true, y_prob), 4))\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_true, y_pred))\n",
    "\n",
    "evaluate_model(\"Logistic Regression\", y_test, y_pred_logreg, y_prob_logreg)\n",
    "evaluate_model(\"Random Forest\", y_test, y_pred_rf, y_prob_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa338b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "fpr_log, tpr_log, _ = roc_curve(y_test, y_prob_logreg)\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_log, tpr_log, label='Logistic Regression', linestyle='--')\n",
    "plt.plot(fpr_rf, tpr_rf, label='Random Forest')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Chance')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve Comparison')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"roc_curve_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nâœ… ROC curve saved as 'roc_curve_comparison.png'.\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
